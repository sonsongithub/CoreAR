<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><script type="text/x-mathjax-config">  MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ["\\(","\\)"]] } });</script><script type="text/javascript"  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script><meta http-equiv="X-UA-Compatible" CONTENT="IE=EmulateIE7" /><title>CoreAR.framework</title></head><body>CoreAR.frameworkの実装方法およびその原理ついて解説してみることにする。まず，2次元コードによるAugmented Reality(以下，AR)を実現するための技術的な課題をまとめる．2次元コードを使い，カメラ画像上に仮想物体を重畳させるARには，以下のことを達成する必要がある．<ol><li>2次元コードのカメラ画像中での4つの頂点の位置を推定する</li><li>2次元コードを識別する</li><li>2次元コードのカメラに対する位置・姿勢を推定する</li><li>2次元コードのカメラに対する位置・姿勢を使って，カメラ画像上に仮想物体を描画する</li></ol>2次元コードのカメラに対する位置・姿勢は，行列$R$と$T$を使って書くことができる．1〜3までの処理は，2次元コードが写った画像$I$とすると，$I$が与えられたときに$R$,$T$を求めることである．ただし，カメラパラメータと2次元コードの大きさが与えられないと，それは計算できない．CoreAR.frameworkでは，カメラパラメータは，焦点距離だけを使っており，その他のカメラの影響は無視している．\[I \Rightarrow R,T\]\[R=\left[ \begin{array}{ccc}r_{1,1} & r_{1,2} & r_{1,3}\\r_{2,1} & r_{2,2} & r_{2,3}\\r_{3,1} & r_{3,2} & r_{3,3}\\\end{array} \right],T=\left[ \begin{array}{c}t_{1}\\t_{2}\\t_{3}\\\end{array} \right],\]ARというと画像処理プログラミングのイメージが先行するが，一般的な画像処理のコーディングは，二値化，チェイン符号化，コードの識別時の画像の正規化くらいしかない．他は，ほとんど幾何と最適化問題になり，ベクトルと行列の演算が主となる．以降，本文では，ベクトルの演算，三角関数，線形台数，同次座標系の最低限の知識を前提条件として説明を進める．それでは，上の3つのおおまかな処理をもう少し詳しくわけて書いてみる．<h3>2次元コードのカメラ画像中での4つの頂点の位置を推定する</h3>この処理は，さらに細分化すると以下の処理に分解される．<ol><li>カメラ画像を二値化する</li><li>カメラ画像をチェイン符号によってコード領域を抜き出す</li><li>不要なコード領域を削除する</li><li>コード領域の4つの頂点を推定する</li><li>コード領域に直線をフィッティングして，さらに厳密に4つの頂点を推定する</li></ol>カメラ画像のピクセルをいじる画像処理は，ここがメインで，二値化，チェインコード符号化がここに含まれる．これら二つの画像処理はそこまで難しくはない．<h3>2次元コードを識別する</h3>2次元コードの識別は，以下の処理に分解される．<ol><li>Homography行列$H$を計算する</li><li>$H$でカメラ画像中の2次元コードを正規化する</li><li>正規化した2次元コード画像を識別する</li></ol>識別で重要な処理は，一つ目のHomography行列$H$の計算だ．$H$は8自由度の3x3の行列である．この行列を使って，カメラ画像中の2次元コードを真正面から正対した正規化画像に戻す．$H$は，上の4つの頂点の画像中での位置を用いて算出する．この後，2次元コードの内容を読み取り，対象を識別する．ここで読み取りに失敗すると，2次元コードの候補領域は棄却される．\[H=\left[ \begin{array}{ccc}h_{1,1} & h_{1,2} & h_{1,3}\\h_{2,1} & h_{2,2} & h_{2,3}\\h_{3,1} & h_{3,2} & 1\\\end{array} \right]\]<h3>2次元コードのカメラに対する位置・姿勢を推定する</h3><ol><li>$ r_{1,3}, r_{2,3}, r_{3,3} $の3つの値をHomography行列$H$から計算する</li><li>2次元コードの大きさを調べる</li><li>2次元コードの大きさから，残りのパラメータ$k$を推定する</li></ol>同次座標表現では，位置・姿勢は，6自由度の4x4の行列$A$で表される．これらの要素を，すでに計算済みのHomography行列$H$から算出していく．\[A=\left[ \begin{array}{cccc} &  &  & 　\\ & R &  & T\\ &  &  & \\0 & 0 & 0 & 1\\\end{array} \right]=\left[ \begin{array}{cccc}r_{1,1} & r_{1,2} & r_{1,3} & t_{1}\\r_{2,1} & r_{2,2} & r_{2,3} & t_{2}\\r_{3,1} & r_{3,2} & r_{3,3} & t_{3}\\0 & 0 & 0 & 1\\\end{array} \right]\]2次元コードの大きさが未定である状態では，$A$は，$k$を自由度として持ってしまうため，2次元コードの大きさを既知として，これを推定する．これは，小さな2次元コードが近くにあるのか．大きな2次元コードが遠くにあるのかが，カメラ画像からは，情報がないため推測できないためである．\[A=\left[\begin{array}{cccc}h_{1,1} & h_{1,2} & r_{1,3} & k \cdot h_{3,1}\\h_{2,1} & h_{2,2} & r_{2,3} & k \cdot h_{3,2}\\h_{3,1} & h_{3,2} & r_{3,3} & k\\0 & 0 & 0 & 1\\\end{array} \right]\]以上で，カメラに対する2次元コードの位置・姿勢の計算は完了する．<h3>2次元コードのカメラに対する位置・姿勢を使って，カメラ画像上に仮想物体を描画する</h3>得られた$R$と$T$を使って，仮想物体をレンダリングするだけだ．このとき，OpenGLを使えば，簡単にレンダリングできる．$R$と$T$をdouble m[16]の中に代入して，glMultMatrixf等を使って座標変換すればよい．他に注意するのは，OpenGLの射影変換にカメラパラメータを反映させることくらいである．<code><br/><br/>double m[16];<br/><br/>// set R and T to m<br/><br/>glPushMatrix();<br/>glMultMatrixf(m);<br/>drawObject();<br/>glPopMatrix();<br/><br/></code><h3>まとめ</h3><ol><li>2次元コードのカメラ画像中での4つの頂点の位置を推定する</li><li>2次元コードを識別する</li><li>2次元コードのカメラに対する位置・姿勢を推定する</li><li>2次元コードのカメラに対する位置・姿勢を使って，カメラ画像上に仮想物体を描画する</li></ol>以上の4つのおおまかな流れで説明していこうと思う．ここまで読んで，「なるほどねー」と思われる方は，もはや，理解されている方なので，私の文章など読む必要はないと思われる．それでは，少しづつ，詳細を説明していこう．</body></html>